# LLM Configuration
# Set these environment variables to override default model selection

# For fast tasks (name generation, commit messages)
# LLM_FAST_MODEL=gemini-flash-lite
# LLM_FAST_MODEL=devstral:latest  # Use Ollama

# For code generation and reasoning
# LLM_CODEGEN_MODEL=sonnet
# LLM_CODEGEN_MODEL=deepseek-r1:32b  # Use Ollama

# For vision and UI analysis
# LLM_VISION_MODEL=gemini-flash-lite
# LLM_VISION_MODEL=qwen2.5vl:32b  # Use Ollama

# Ollama configuration (required when using Ollama models)
# OLLAMA_HOST=http://localhost:11434

# Provider API keys
# ANTHROPIC_API_KEY=your_key_here
# GEMINI_API_KEY=your_key_here
