# LLM Configuration
# Set these environment variables to override default model selection

# For best coding tasks (slow, high quality)
# LLM_BEST_CODING_MODEL=sonnet
# LLM_BEST_CODING_MODEL=devstral:latest  # Use Ollama

# For universal tasks (medium speed, FSM tools)
# LLM_UNIVERSAL_MODEL=gemini-flash
# LLM_UNIVERSAL_MODEL=llama3.1  # Use Ollama

# For ultra fast tasks (commit names etc)
# LLM_ULTRA_FAST_MODEL=gemini-flash-lite
# LLM_ULTRA_FAST_MODEL=gemma3  # Use Ollama

# For vision and UI analysis
# LLM_VISION_MODEL=gemini-flash-lite
# LLM_VISION_MODEL=qwen2.5vl:32b  # Use Ollama

# Ollama configuration (required when using Ollama models)
# OLLAMA_HOST=http://localhost:11434

# Provider API keys
# ANTHROPIC_API_KEY=your_key_here
# GEMINI_API_KEY=your_key_here
